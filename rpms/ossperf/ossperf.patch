diff --git a/ossperf.sh b/ossperf.sh
index 1009bf5..677fc43 100755
--- a/ossperf.sh
+++ b/ossperf.sh
@@ -31,7 +31,7 @@ command -v ping >/dev/null 2>&1 || { echo >&2 "ossperf requires the command line
 
 function usage
 {
-echo "$SCRIPT -n files -s size [-b <bucket>] [-u] [-a] [-m <alias>] [-z] [-g] [-k] [-p] [-o]
+echo "$SCRIPT -n files -s size [-b <bucket>] [-c <config file>] [-u] [-a] [-m <alias>] [-z] [-g] [-k] [-p] [-o]
 
 This script analyzes the performance and data integrity of S3-compatible
 storage services 
@@ -39,7 +39,8 @@ storage services
 Arguments:
 -h : show this message on screen
 -n : number of files to be created
--s : size of the files to be created in bytes (max 16777216 = 16 MB)
+-s : size of the files to be created in bytes
+-c : configuration file for s3cmd
 -b : ossperf will create per default a new bucket ossperf-testbucket (or OSSPERF-TESTBUCKET, in case the argument -u is set). This is not a problem when private cloud deployments are investigated, but for public cloud scenarios it may become a problem, because object-based stoage services implement a global bucket namespace. This means that all bucket names must be unique. With the argument -b <bucket> the users of ossperf have the freedom to specify the bucket name
 -u : use upper-case letters for the bucket name (this is required for Nimbus Cumulus and S3ninja)
 -a : use the Swift API and not the S3 API (this requires the python client for the Swift API and the environment variables ST_AUTH, ST_USER and ST_KEY)
@@ -67,6 +68,7 @@ NOT_CLEAN_UP=0
 PARALLEL=0
 LIST_OF_FILES=
 OUTPUT_FILE=0
+S3CMD_CONFIG=""
 
 RED='\033[0;31m'          # Red color
 NC='\033[0m'              # No color
@@ -75,7 +77,7 @@ YELLOW='\033[0;33m'       # Yellow color
 BLUE='\033[0;34m'         # Blue color
 WHITE='\033[0;37m'        # White color
 
-while getopts "hn:s:b:uamzgkpo" Arg ; do
+while getopts "hn:s:b:c:uamzgkpo" Arg ; do
   case $Arg in
     h) usage ;;
     n) NUM_FILES=$OPTARG ;;
@@ -83,6 +85,8 @@ while getopts "hn:s:b:uamzgkpo" Arg ; do
     # If the flag has been set => $NOT_CLEAN_UP gets value 1
     b) BUCKETNAME_PARAMETER=1
        BUCKET=$OPTARG ;; 
+    c) CONFIGFILE=1 
+       CONFIG_FILENAME=$OPTARG ;;
     u) UPPERCASE=1 ;;
     a) SWIFT_API=1 ;;
     m) MINIO_CLIENT=1 
@@ -99,6 +103,9 @@ while getopts "hn:s:b:uamzgkpo" Arg ; do
 done
 
 
+if [ "$CONFIGFILE" -eq 1 ] ; then
+   S3CMD_CONFIG="-c $CONFIG_FILENAME"
+fi
 # Only if the user wants to execute the upload and dowload of the files in parallel...
 if [ "$PARALLEL" -eq 1 ] ; then
   # ... the script needs to check, if the command line tool GNU parallel is installed
@@ -191,35 +198,36 @@ if [ "$NUM_FILES" -eq 0 ] ; then
   exit 1
 fi
 
+# Commented the file size restriction
 # Validate that...
 # SIZE_FILES is not 0 and not bigger than 16777216
-if ( [[ "$SIZE_FILES" -eq 0 ]] || [[ "$SIZE_FILES" -gt 16777216 ]] ) ; then
-   echo -e "${RED}Attention: The size of the file(s) must not 0 and the maximum size is 16.777.216 Byte!${NC}"
-   usage
-   exit 1
-fi
- 
+#if ( [[ "$SIZE_FILES" -eq 0 ]] || [[ "$SIZE_FILES" -gt 16777216 ]] ) ; then
+#   echo -e "${RED}Attention: The size of the file(s) must not 0 and the maximum size is 16.777.216 Byte!${NC}"
+#   usage
+#   exit 1
+#fi
  
+# Commented the internet check, not needed for S3server
 # We shall check at least 5 times
-LOOP_VARIABLE=5  
+#LOOP_VARIABLE=5  
 #until LOOP_VARIABLE is greater than 0 
-while [ $LOOP_VARIABLE -gt "0" ]; do 
+#while [ $LOOP_VARIABLE -gt "0" ]; do 
   # Check if we have a working network connection by sending a ping to 8.8.8.8
-  if ping -q -c 1 -W 1 8.8.8.8 >/dev/null ; then
-    echo -e "${GREEN}[OK] This computer has a working internet connection.${NC}"
+#  if ping -q -c 1 -W 1 8.8.8.8 >/dev/null ; then
+#    echo -e "${GREEN}[OK] This computer has a working internet connection.${NC}"
     # Skip entire rest of loop.
-    break
-  else
-    echo -e "${YELLOW}[INFO] The internet connection is not working now. Will check again.${NC}"
+#    break
+#  else
+#    echo -e "${YELLOW}[INFO] The internet connection is not working now. Will check again.${NC}"
     # Decrement variable
-    LOOP_VARIABLE=$((LOOP_VARIABLE-1))
-    if [ "LOOP_VARIABLE" -eq 0 ] ; then
-      echo -e "${RED}[ERROR] This computer has no working internet connection. Please check your network settings.${NC}" && exit 1
-    fi
+#    LOOP_VARIABLE=$((LOOP_VARIABLE-1))
+#    if [ "LOOP_VARIABLE" -eq 0 ] ; then
+#      echo -e "${RED}[ERROR] This computer has no working internet connection. Please check your network settings.${NC}" && exit 1
+#    fi
     # Wait a moment. 
-    sleep 1
-  fi
-done
+#    sleep 1
+#  fi
+#done
 
 
 
@@ -296,7 +304,7 @@ elif [ "$GOOGLE_API" -eq 1 ] ; then
   fi
 else
   # use the S3 API with s3cmd
-  if s3cmd mb s3://$BUCKET ; then
+  if s3cmd $S3CMD_CONFIG  mb s3://$BUCKET ; then
     echo -e "${GREEN}[OK] Bucket ${BUCKET} has been created.${NC}"
   else
     echo -e "${RED}[ERROR] Unable to create the bucket ${BUCKET}.${NC}" && exit 1
@@ -326,7 +334,7 @@ if [ "$SWIFT_API" -ne 1 ] ; then
   # until LOOP_VARIABLE is greater than 0 
   while [ $LOOP_VARIABLE -gt "0" ]; do 
     # Check if the Bucket is accessible
-    if s3cmd ls s3://$BUCKET ; then
+    if s3cmd $S3CMD_CONFIG ls s3://$BUCKET ; then
       echo -e "${GREEN}[OK] The bucket is available.${NC}"
       # Skip entire rest of loop.
       break
@@ -389,7 +397,7 @@ if [ "$PARALLEL" -eq 1 ] ; then
   else
   # use the S3 API with s3cmd
     # Upload files in parallel
-    if find $DIRECTORY/*.txt | parallel s3cmd put {} s3://$BUCKET ; then
+    if find $DIRECTORY/*.txt | parallel s3cmd $S3CMD_CONFIG put {} s3://$BUCKET ; then
       echo -e "${GREEN}[OK] Files have been uploaded.${NC}"
     else
       echo -e "${RED}[ERROR] Unable to upload the files.${NC}" && exit 1
@@ -434,7 +442,7 @@ else
   else
   # use the S3 API with s3cmd
     # Upload files sequentially
-    if s3cmd put $DIRECTORY/*.txt s3://$BUCKET ; then
+    if s3cmd $S3CMD_CONFIG put $DIRECTORY/*.txt s3://$BUCKET ; then
       echo -e "${GREEN}[OK] Files have been uploaded.${NC}"
     else
       echo -e "${RED}[ERROR] Unable to upload the files.${NC}" && exit 1
@@ -503,7 +511,7 @@ elif [ "$GOOGLE_API" -eq 1 ] ; then
   fi
 else
   # use the S3 API with s3cmd
-  if s3cmd ls s3://$BUCKET ; then
+  if s3cmd $S3CMD_CONFIG ls s3://$BUCKET ; then
     echo -e "${GREEN}[OK] The list of objects inside ${BUCKET} has been fetched.${NC}"
   else
     echo -e "${RED}[ERROR] Unable to fetch the list of objects inside ${BUCKET}.${NC}" && exit 1
@@ -568,7 +576,7 @@ if [ "$PARALLEL" -eq 1 ] ; then
   else
   # use the S3 API with s3cmd
     # Download files in parallel
-    if find ${DIRECTORY}/*.txt -type f -printf "%f\n" | parallel s3cmd get --force s3://$BUCKET/{} $DIRECTORY/ ; then
+    if find ${DIRECTORY}/*.txt -type f -printf "%f\n" | parallel s3cmd $S3CMD_CONFIG get --force s3://$BUCKET/{} $DIRECTORY/ ; then
       echo -e "${GREEN}[OK] Files have been downloaded.${NC}"
     else
       echo -e "${RED}[ERROR] Unable to download the files.${NC}" && exit 1
@@ -616,7 +624,7 @@ else
   else
   # use the S3 API with s3cmd
     # Download files sequentially
-    if s3cmd get --force s3://$BUCKET/*.txt $DIRECTORY/ ; then
+    if s3cmd $S3CMD_CONFIG get --force s3://$BUCKET/*.txt $DIRECTORY/ ; then
       echo -e "${GREEN}[OK] Files have been downloaded.${NC}"
     else
       echo -e "${RED}[ERROR] Unable to download the files.${NC}" && exit 1
@@ -702,7 +710,7 @@ if [ "$PARALLEL" -eq 1 ] ; then
   else
   # use the S3 API with s3cmd
     #  Erase files (objects) inside the bucket in parallel
-    if find $DIRECTORY/*.txt | parallel s3cmd del --recursive s3://$BUCKET/* ; then
+    if find $DIRECTORY/*.txt -type f -printf "%f\n" | parallel s3cmd $S3CMD_CONFIG del s3://$BUCKET/{} ; then
       echo -e "${GREEN}[OK] Files inside the bucket ${BUCKET} have been erased.${NC}"
     else
       echo -e "${RED}[ERROR] Unable to erase the files inside the bucket ${BUCKET}.${NC}" && exit 1
@@ -747,7 +755,7 @@ else
   else
   # use the S3 API with s3cmd
     # Erase files (objects) inside the bucket sequentially
-    if s3cmd del s3://$BUCKET/* ; then
+    if s3cmd $S3CMD_CONFIG del s3://$BUCKET/* ; then
       echo -e "${GREEN}[OK] Files inside the bucket ${BUCKET} have been erased.${NC}"
     else
       echo -e "${RED}[ERROR] Unable to erase the files inside the bucket ${BUCKET}.${NC}" && exit 1
@@ -844,7 +852,7 @@ elif [ "$GOOGLE_API" -eq 1 ] ; then
   fi
 else
   # use the S3 API with s3cmd
-  if s3cmd rb --force --recursive s3://$BUCKET ; then
+  if s3cmd $S3CMD_CONFIG rb --force --recursive s3://$BUCKET ; then
     echo -e "${GREEN}[OK] Bucket ${BUCKET} has been erased.${NC}"
   else
     echo -e "${RED}[ERROR] Unable to erase the bucket ${BUCKET}.${NC}" && exit 1
